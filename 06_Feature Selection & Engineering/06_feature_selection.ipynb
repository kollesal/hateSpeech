{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Feature Selection and Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of required libraries\n",
    "Those libraries are used in the notebook to perform the data preparation. Maybee you need to install them first with `pip install <library>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pandas import json_normalize\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io import sql\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Read file into dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_tweets \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m04_Data Cleansing\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m04_cleaned_data.csv\u001b[39m\u001b[39m'\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(df_tweets\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      4\u001b[0m df_tweets\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read file into dataframe\n",
    "df_tweets = pd.read_csv('..\\\\04_Data Cleansing\\\\04_cleaned_data.csv', sep=',', encoding='utf-8')\n",
    "print(df_tweets.shape)\n",
    "df_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>senderuser_id</th>\n",
       "      <th>receiveruser_id</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>interaction_timestamp</th>\n",
       "      <th>char_count</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1304</td>\n",
       "      <td>1510</td>\n",
       "      <td>876</td>\n",
       "      <td>2009</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>41:34.9</td>\n",
       "      <td>20</td>\n",
       "      <td>@gyu What is that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>31503</td>\n",
       "      <td>918</td>\n",
       "      <td>2436</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "      <td>37:48.7</td>\n",
       "      <td>16</td>\n",
       "      <td>@stockputout yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2533</td>\n",
       "      <td>27942</td>\n",
       "      <td>1409</td>\n",
       "      <td>3624</td>\n",
       "      <td>other_cyberbullying</td>\n",
       "      <td>50:46.1</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2598</td>\n",
       "      <td>52129</td>\n",
       "      <td>1341</td>\n",
       "      <td>3290</td>\n",
       "      <td>none</td>\n",
       "      <td>04:51.4</td>\n",
       "      <td>26</td>\n",
       "      <td>@Blackamazon EXACTLY THIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3511</td>\n",
       "      <td>54626</td>\n",
       "      <td>831</td>\n",
       "      <td>2812</td>\n",
       "      <td>none</td>\n",
       "      <td>11:11.2</td>\n",
       "      <td>34</td>\n",
       "      <td>@Oddtankout http   t co KmMJEUME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   interaction_id  tweet_id  senderuser_id  receiveruser_id  \\\n",
       "0            1304      1510            876             2009   \n",
       "1            1998     31503            918             2436   \n",
       "2            2533     27942           1409             3624   \n",
       "3            2598     52129           1341             3290   \n",
       "4            3511     54626            831             2812   \n",
       "\n",
       "    cyberbullying_type interaction_timestamp  char_count  \\\n",
       "0    not_cyberbullying               41:34.9          20   \n",
       "1  other_cyberbullying               37:48.7          16   \n",
       "2  other_cyberbullying               50:46.1           7   \n",
       "3                 none               04:51.4          26   \n",
       "4                 none               11:11.2          34   \n",
       "\n",
       "                         tweet_text  \n",
       "0                @gyu What is that   \n",
       "1                  @stockputout yes  \n",
       "2                                    \n",
       "3        @Blackamazon EXACTLY THIS   \n",
       "4  @Oddtankout http   t co KmMJEUME  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'tweet_text'\n",
    "df_tweets.drop(columns=['tweet_text'], inplace=True)\n",
    "\n",
    "# Rename the 'cleaned' column to 'tweet_text' and length\n",
    "df_tweets.rename(columns={'cleaned': 'tweet_text'}, inplace=True)\n",
    "df_tweets.rename(columns={'length': 'char_count'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame after the changes\n",
    "df_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not_cyberbullying', 'other_cyberbullying', 'none', 'gender',\n",
       "       'sexism', 'age', 'ethnicity', 'religion', 'racism', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['cyberbullying_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all the text to uppercase\n",
    "df_tweets['tweet_text'] = df_tweets['tweet_text'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:15: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['harass'] = df_tweets['tweet_text'].str.contains(pat = patternHarass).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3285.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:17: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['cyberstalk'] = df_tweets['tweet_text'].str.contains(pat = patternCyberstalk).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2288.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:19: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['flaming'] = df_tweets['tweet_text'].str.contains(pat = patternFlaming).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:21: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['outing'] = df_tweets['tweet_text'].str.contains(pat = patternOuting).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:23: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['doxing'] = df_tweets['tweet_text'].str.contains(pat = patternDoxing).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:25: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['exclusion'] = df_tweets['tweet_text'].str.contains(pat = patternExclusion).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:27: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['impersonation'] = df_tweets['tweet_text'].str.contains(pat = patternImpersonation).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:29: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['trolling'] = df_tweets['tweet_text'].str.contains(pat = patternTrolling).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1004.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:31: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['hateSpeech'] = df_tweets['tweet_text'].str.contains(pat = patternHateSpeech).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6890.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_21152\\2045690740.py:33: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_tweets['threats'] = df_tweets['tweet_text'].str.contains(pat = patternThreats).astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>harass</th>\n",
       "      <th>cyberstalk</th>\n",
       "      <th>flaming</th>\n",
       "      <th>outing</th>\n",
       "      <th>doxing</th>\n",
       "      <th>exclusion</th>\n",
       "      <th>impersonation</th>\n",
       "      <th>trolling</th>\n",
       "      <th>hateSpeech</th>\n",
       "      <th>threats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@GYU WHAT IS THAT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@STOCKPUTOUT YES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BLACKAMAZON EXACTLY THIS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ODDTANKOUT HTTP   T CO KMMJEUME</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64339</th>\n",
       "      <td>ONLY THING THAT HEATS MY HEAD MORE IS WHEN I S...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64340</th>\n",
       "      <td>FOUND OUT THE GIRL WHO SPREAD (TRUE) RUMOURS A...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64341</th>\n",
       "      <td>NIÑAS  REINAS DEL “BULLYING” EN ESCUELAS PRIVA...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64342</th>\n",
       "      <td>@DIANH AS USUAL  YOU ARE A MUSLIM LIAR MAKING ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64343</th>\n",
       "      <td>THOSE  MAKING IT THROUGH TO THE NEXT ROUND  CO...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64344 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text  harass  cyberstalk  \\\n",
       "0                                     @GYU WHAT IS THAT      0.0         0.0   \n",
       "1                                       @STOCKPUTOUT YES     0.0         0.0   \n",
       "2                                                            0.0         0.0   \n",
       "3                             @BLACKAMAZON EXACTLY THIS      0.0         0.0   \n",
       "4                       @ODDTANKOUT HTTP   T CO KMMJEUME     0.0         0.0   \n",
       "...                                                  ...     ...         ...   \n",
       "64339  ONLY THING THAT HEATS MY HEAD MORE IS WHEN I S...     0.0         0.0   \n",
       "64340  FOUND OUT THE GIRL WHO SPREAD (TRUE) RUMOURS A...     0.0         0.0   \n",
       "64341  NIÑAS  REINAS DEL “BULLYING” EN ESCUELAS PRIVA...     1.0         0.0   \n",
       "64342  @DIANH AS USUAL  YOU ARE A MUSLIM LIAR MAKING ...     0.0         0.0   \n",
       "64343  THOSE  MAKING IT THROUGH TO THE NEXT ROUND  CO...     0.0         0.0   \n",
       "\n",
       "       flaming  outing  doxing  exclusion  impersonation  trolling  \\\n",
       "0          0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "1          0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "2          0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "3          0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "4          0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "...        ...     ...     ...        ...            ...       ...   \n",
       "64339      0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "64340      0.0     0.0     1.0        0.0            1.0       0.0   \n",
       "64341      0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "64342      0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "64343      0.0     0.0     0.0        0.0            0.0       0.0   \n",
       "\n",
       "       hateSpeech  threats  \n",
       "0             0.0      0.0  \n",
       "1             0.0      0.0  \n",
       "2             0.0      0.0  \n",
       "3             0.0      0.0  \n",
       "4             0.0      0.0  \n",
       "...           ...      ...  \n",
       "64339         0.0      0.0  \n",
       "64340         0.0      0.0  \n",
       "64341         0.0      0.0  \n",
       "64342         0.0      0.0  \n",
       "64343         0.0      0.0  \n",
       "\n",
       "[64344 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatGTP has created the pattern \n",
    "# Create a pattern which can be used to search the variable 'tweet_text'\n",
    "patternHarass = '(INSULT)|(ABUSE)|(THREATEN)|(VICTIM)|(TORMENT)|(PERSECUTE)|(INTIMIDATE)|(AGGRESSION)|(RELENTLESS)|(BULLYING)|(HOSTILITY)|(SLANDER)|(HURTFUL)|(ATTACKS)|(OFFENSE)|(MALICIOUS)|(STALKER)|(TAUNT)|(ABUSIVE)|(TARGET)'\n",
    "patternCyberstalk = '(STALK)|(PURSUE)|(OBSESS)|(WATCH)|(FOLLOW)|(INTRUDE)|(SPY)|(UNWANTED)|(MONITORING)|(SURVEILLANCE)|(TRACKING)|(INVASION)|(SHADOW)|(PRYING)|(PERSISTENCE)|(STALKING)|(SPYING)|(INTRUSIVE)|(PERVASION)|(PURSUIT)'\n",
    "patternFlaming = '(PROVOCATION)|(INSULTING)|(AGGRESSIVE)|(HOSTILE)|(OFFEND)|(HEATED)|(ARGUMENTATIVE)|(OFFENSIVE)|(CONTENTIOUS)|(DISPUTE)|(ANTAGONISTIC)|(FIERY)|(INCENDIARY)|(HARSH)|(COMBATIVE)|(CLASHING)|(ARGUMENT)|(PROVOCATIVE)|(SPARRING)|(CONTROVERSIAL)'\n",
    "patternOuting = '(EXPOSURE)|(REVEAL)|(DISCLOSURE)|(BETRAYAL)|(UNMASKING)|(UNVEILING)|(LEAKAGE)|(PUBLICATION)|(BETRAYED)|(UNCOVERING)|(EXPOSED)|(CONFESSION)|(REVEALING)|(LEAKED)|(PRIVACY)|(PRIVATE)|(DATA)|(DETAILS)|(IDENTIFY)|(PUBLISH)'\n",
    "patternDoxing = '(DOX)|(INFORMATION)|(REVEAL)|(DATA)|(PERSONAL)|(IDENTITY)|(PRIVACY)|(EXPOSED)|(PUBLISH)|(UNMASKING)|(LEAKED)|(PROFILE)|(ADDRESS)|(DETAILS)|(IDENTIFY)|(PUBLISH)|(REVEALING)|(EXPOSE)|(DATA)|(UNVEILING)'\n",
    "patternExclusion = '(ISOLATE)|(OSTRACIZE)|(EXCLUDE)|(ALIENATION)|(SHUN)|(REJECT)|(IGNORED)|(OUTSIDER)|(SOLITUDE)|(SEGREGATE)|(ABANDONMENT)|(NEGLECTED)|(ISOLATED)|(MARGINALIZED)|(UNWANTED)|(LONELINESS)|(REJECTION)|(ISOLATION)|(NEGLECT)|(NEGLECTING)'\n",
    "patternImpersonation = '(FAKE)|(IDENTITY)|(DECEPTION)|(FRAUDULENT)|(PRETEND)|(IMITATE)|(COUNTERFEIT)|(MIMIC)|(PHONY)|(FRAUD)|(FORGERY)|(IMPOSTER)|(DECEIVER)|(FAKE PROFILE)|(FALSE IDENTITY)|(IDENTITY THEFT)|(FRAUDULENT ACCOUNT)|(MIMICKING)|(FORGED)|(COUNTERFEITING)'\n",
    "patternTrolling = '(TROLL)|(PROVOCATION)|(AGITATION)|(DISRUPTION)|(ANNOYING)|(NUISANCE)|(IRRITATION)|(HARASSMENT)|(MISCHIEF)|(TEASING)|(INSTIGATION)|(OFFENSIVE)|(MOCKERY)|(RIDICULE)|(TAUNT)|(DISTURBANCE)|(BAITING)|(ANTAGONISTIC)|(CONTROVERSIAL)|(PRANKS)'\n",
    "patternHateSpeech = '(HATE)|(BIGOTRY)|(DISCRIMINATION)|(PREJUDICE)|(STEREOTYPING)|(HOMOPHOBIA)|(MISOGYNY)|(RACIAL)|(SLURS)|(XENOPHOBIA)|(BIAS)|(OFFENSIVE)|(DEROGATORY)|(VILE)|(PREJUDICED)|(HATE-FILLED)|(INTOLERANCE)|(RACIST)|(SEXIST)|(HOMOPHOBIC)'\n",
    "patternThreats = '(THREATEN)|(VIOLENCE)|(DANGER)|(MENACE)|(INTIMIDATE)|(HARM)|(PERIL)|(WARNING)|(COERCION)|(FEAR)|(HARBINGER)|(TERRORIZE)|(MENACING)|(ASSAULT)|(HOSTILITY)|(AGGRESSION)|(THREATENING)|(THREATENED)|(ABUSIVE)|(VIOLENT)'\n",
    "\n",
    "# Create new variable 'luxurious' as binary dummy (0/1) variable\n",
    "df_tweets['harass'] = df_tweets['tweet_text'].str.contains(pat = patternHarass).astype(float)\n",
    "print(df_tweets['harass'].sum())\n",
    "df_tweets['cyberstalk'] = df_tweets['tweet_text'].str.contains(pat = patternCyberstalk).astype(float)\n",
    "print(df_tweets['cyberstalk'].sum())\n",
    "df_tweets['flaming'] = df_tweets['tweet_text'].str.contains(pat = patternFlaming).astype(float)\n",
    "print(df_tweets['flaming'].sum())\n",
    "df_tweets['outing'] = df_tweets['tweet_text'].str.contains(pat = patternOuting).astype(float)\n",
    "print(df_tweets['outing'].sum())\n",
    "df_tweets['doxing'] = df_tweets['tweet_text'].str.contains(pat = patternDoxing).astype(float)\n",
    "print(df_tweets['doxing'].sum())\n",
    "df_tweets['exclusion'] = df_tweets['tweet_text'].str.contains(pat = patternExclusion).astype(float)\n",
    "print(df_tweets['exclusion'].sum())\n",
    "df_tweets['impersonation'] = df_tweets['tweet_text'].str.contains(pat = patternImpersonation).astype(float)\n",
    "print(df_tweets['impersonation'].sum())\n",
    "df_tweets['trolling'] = df_tweets['tweet_text'].str.contains(pat = patternTrolling).astype(float)\n",
    "print(df_tweets['trolling'].sum())\n",
    "df_tweets['hateSpeech'] = df_tweets['tweet_text'].str.contains(pat = patternHateSpeech).astype(float)\n",
    "print(df_tweets['hateSpeech'].sum())\n",
    "df_tweets['threats'] = df_tweets['tweet_text'].str.contains(pat = patternThreats).astype(float)\n",
    "print(df_tweets['threats'].sum())\n",
    "\n",
    "# Show values\n",
    "df_tweets[['tweet_text','harass','cyberstalk','flaming','outing', 'doxing', 'exclusion', 'impersonation', 'trolling', 'hateSpeech', 'threats']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@GYU WHAT IS THAT</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@STOCKPUTOUT YES</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BLACKAMAZON EXACTLY THIS</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ODDTANKOUT HTTP   T CO KMMJEUME</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         tweet_text  word_count  char_count\n",
       "0                @GYU WHAT IS THAT            4          20\n",
       "1                  @STOCKPUTOUT YES           2          16\n",
       "2                                             0           7\n",
       "3        @BLACKAMAZON EXACTLY THIS            3          26\n",
       "4  @ODDTANKOUT HTTP   T CO KMMJEUME           5          34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets['word_count'] = df_tweets['tweet_text'].apply(lambda x: len(str(x).split()))\n",
    "df_tweets[['tweet_text', 'word_count', 'char_count']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code has been generated by ChatGPT\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Custom functions to calculate text statistics\n",
    "def average_word_length(tweet_text):\n",
    "    if isinstance(tweet_text, str) and len(tweet_text) > 0:\n",
    "        words = word_tokenize(tweet_text)\n",
    "        return sum(len(word) for word in words) / len(words) if len(words) > 0 else 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def average_sentence_length(tweet_text):\n",
    "    if isinstance(tweet_text, str) and len(tweet_text) > 0:\n",
    "        sentences = sent_tokenize(tweet_text)\n",
    "        return len(word_tokenize(tweet_text)) / len(sentences) if len(sentences) > 0 else 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def count_punctuation(tweet_text):\n",
    "    if isinstance(tweet_text, str):\n",
    "        return sum(1 for char in tweet_text if char in string.punctuation)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply custom functions to calculate text statistics\n",
    "df_tweets['avg_word_length'] = df_tweets['tweet_text'].apply(average_word_length)\n",
    "df_tweets['avg_sentence_length'] = df_tweets['tweet_text'].apply(average_sentence_length)\n",
    "df_tweets['punctuation_count'] = df_tweets['tweet_text'].apply(count_punctuation)\n",
    "\n",
    "# Display the DataFrame with text statistics\n",
    "df_tweets[['tweet_text', 'avg_word_length', 'avg_sentence_length', 'punctuation_count']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_values_count = (df_tweets['avg_word_length'] == 0).sum()\n",
    "print(f'Number of 0 values in avg_word_length: {zero_values_count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check, on how many 0 Values have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries with avg_word_length as 0: 11\n",
      "Number of entries with avg_sentence_length as 0: 11\n",
      "Number of entries with punctuation_count as 0: 29609\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of entries with avg_word_length as 0: {(df_tweets[\"avg_word_length\"] == 0).sum()}')\n",
    "print(f'Number of entries with avg_sentence_length as 0: {(df_tweets[\"avg_sentence_length\"] == 0).sum()}')\n",
    "print(f'Number of entries with punctuation_count as 0: {(df_tweets[\"punctuation_count\"] == 0).sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the ones that have 0 as a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tweet_text  avg_word_length\n",
      "2                             0.0\n",
      "145                           0.0\n",
      "212                           0.0\n",
      "3434                          0.0\n",
      "7304                          0.0\n",
      "13327                         0.0\n",
      "15911                         0.0\n",
      "33643        NaN              0.0\n",
      "40379                         0.0\n",
      "56275                         0.0\n",
      "63881                         0.0\n"
     ]
    }
   ],
   "source": [
    "print(df_tweets[df_tweets['avg_word_length'] == 0][['tweet_text', 'avg_word_length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tweet_text  avg_sentence_length\n",
      "2                                 0.0\n",
      "145                               0.0\n",
      "212                               0.0\n",
      "3434                              0.0\n",
      "7304                              0.0\n",
      "13327                             0.0\n",
      "15911                             0.0\n",
      "33643        NaN                  0.0\n",
      "40379                             0.0\n",
      "56275                             0.0\n",
      "63881                             0.0\n"
     ]
    }
   ],
   "source": [
    "print(df_tweets[df_tweets['avg_sentence_length'] == 0][['tweet_text', 'avg_sentence_length']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweet_text  punctuation_count\n",
      "2                                                                         0\n",
      "5                                                   ROFL                  0\n",
      "6                               OH  YES HE IS A BAD GUY                   0\n",
      "7                                 HTTP   T CO NXGTQSLCHG                  0\n",
      "9                                         GAY RAPE JOKE                   0\n",
      "...                                                  ...                ...\n",
      "64334  STILL DOESN T CHANGE THE FACT THAT YOU ARE A P...                  0\n",
      "64336  I AM A WHITE FEMALE  EVERY DAY IN HIGH SCHOOL ...                  0\n",
      "64338   MKR HEY PETE  MAYBE WHAT THOSE KIDS NEED IS S...                  0\n",
      "64339  ONLY THING THAT HEATS MY HEAD MORE IS WHEN I S...                  0\n",
      "64341  NIÑAS  REINAS DEL “BULLYING” EN ESCUELAS PRIVA...                  0\n",
      "\n",
      "[29609 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_tweets[df_tweets['punctuation_count'] == 0][['tweet_text', 'punctuation_count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ones that have 0 values are explainable due to the values presented, like the punctuation count is 0 because there is no punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interaction_id             int64\n",
       "tweet_id                   int64\n",
       "senderuser_id              int64\n",
       "receiveruser_id            int64\n",
       "cyberbullying_type        object\n",
       "interaction_timestamp     object\n",
       "char_count                 int64\n",
       "tweet_text                object\n",
       "harass                   float64\n",
       "cyberstalk               float64\n",
       "flaming                  float64\n",
       "outing                   float64\n",
       "doxing                   float64\n",
       "exclusion                float64\n",
       "impersonation            float64\n",
       "trolling                 float64\n",
       "hateSpeech               float64\n",
       "threats                  float64\n",
       "word_count                 int64\n",
       "avg_word_length          float64\n",
       "avg_sentence_length      float64\n",
       "punctuation_count          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.to_csv('..\\\\06_Feature Selection & Engineering\\\\06_dataset_tweets_featured.csv',\n",
    "                      sep=\",\",\n",
    "                      encoding='utf-8',\n",
    "                      index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
