{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "After data preparation and the model evaluation I want know to train the model with the whole data and check it with a real and fake news article to check the trained model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of required libraries\n",
    "Those libraries are used in the notebook to perform the data preparation. Maybee you need to install them first with `pip install <library>`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "%matplotlib inline\n",
    "\n",
    "#Handling Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Text pre-processing\n",
    "from nltk.corpus import stopwords\n",
    "import string, re\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "#Modeling\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM,Dropout\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "#Deep Learning\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset\n",
    "As first step I will import the cleaned dataset from the previous notebook \"01_data_prep\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('../Machine_Learning2_Project/20_model_evaluation/20_cleaned_data.csv')\n",
    "new_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column \"Unnamed: 0\" is the index column but it is not needed anymore. So I will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_data['Unnamed: 0']\n",
    "new_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think there could be some issues with the values \"Real\" and \"Fake\" in the model training, so I decided to change the Values into \"1\" for \"Real\" and \"0\" for \"Fake\". With the numbers I can easier work with the values in the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'Real': 1, 'Fake': 0}\n",
    "new_data['real/fake'] = new_data['real/fake'].map(mapping)\n",
    "new_data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also noticed that the slash in the name of the column \"real/fake\" becomes a problem later on in the notebook, so I change the name of the column to \"classification\" here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.rename(columns={'real/fake': 'classification'}, inplace=True)\n",
    "new_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As preparation for the training I will create a new dataframe. In this dataframe is split into train, dev and test data with the ratio 60%, 20% and 20%. The reproduce the testing results I will set the random state to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "def train_dev_test_split(df, target_col, proportions):\n",
    "\n",
    "    assert(sum(proportions) == 1.0)\n",
    "    train_size, dev_size, test_size = proportions\n",
    "    \n",
    "    false_index = df[df[target_col] == 1].index\n",
    "    true_index = df[df[target_col] == 0].index\n",
    "    \n",
    "    false_train_indices = np.random.choice(false_index, int(train_size * len(false_index)), replace=False)\n",
    "    true_train_indices = np.random.choice(true_index, int(train_size * len(true_index)), replace=False)\n",
    "    train_indices = list(false_train_indices) + list(true_train_indices)\n",
    "    train = df.iloc[train_indices]\n",
    "\n",
    "    rem_df = df.iloc[list(set(df.index)-set(train_indices))]\n",
    "    rem_false_index = rem_df[rem_df[target_col] == 1].index\n",
    "    rem_true_index = rem_df[rem_df[target_col] == 0].index\n",
    "    false_dev_indices = np.random.choice(rem_false_index, int((dev_size / (dev_size + test_size)) * len(rem_false_index)), replace=False)\n",
    "    true_dev_indices = np.random.choice(rem_true_index, int((dev_size / (dev_size + test_size)) * len(rem_true_index)), replace=False)\n",
    "    dev_indices = list(false_dev_indices) + list(true_dev_indices)\n",
    "    dev = df.iloc[dev_indices]\n",
    "\n",
    "    test_indices = list(set(df.index) - set(train_indices + dev_indices))\n",
    "    test = df.iloc[test_indices]\n",
    "    return train, dev, test\n",
    "\n",
    "train, dev, test = train_dev_test_split(new_data, 'classification', (0.6, 0.2, 0.2))\n",
    "X_train, X_dev, X_test = train.news, dev.news, test.news\n",
    "y_train, y_dev, y_test = train.classification, dev.classification, test.classification\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the datasplit in the train, dev and test data. They should have similar ratios of real and fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='classification', data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='classification', data=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='classification', data=test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are good, so let's use it for the next steps.\n",
    "\n",
    "In the next step, I limit the number of words (features) to 10,000 in the vocabulary and the number of words within a news story to 300 words. I do this to reduce the \"size\" of the model a bit and also because this is a classification and not a large language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "max_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tokenizer on the training data\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad each set of texts\n",
    "tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(tokenized_train, maxlen=max_len)\n",
    "\n",
    "tokenized_dev = tokenizer.texts_to_sequences(X_dev)\n",
    "X_dev = pad_sequences(tokenized_dev, maxlen=max_len)\n",
    "\n",
    "tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(tokenized_test, maxlen=max_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "The first step in the model is to use the GloVe embedding to assign each word to a feature vector which has some meaning in the context of the model, instead of an arbitrary token. For this I will use the GloVe embeddings from an external source.\n",
    "\n",
    "The embedding file is quite large and will not fitt into the github repository. So please download the file from this source: https://www.kaggle.com/datasets/bertcarremans/glovetwitter27b100dtxt and save it in the folder \"Machine_Learning2_Project/30_train_model/30_inputs\" or change the source path in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../Machine_Learning2_Project/30_train_model/30_inputs/30_glove.twitter.27B.100d.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will create a dictionary with the GloVe embeddings. The dictionary will contain the word as key and the embedding as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict((get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf-8')))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on the dictionary, I create an embedding matrix that contains the embedded representations for the words that occur in the pre-processed text. This matrix can then be used in an NLP model as part of the embedding layer to learn the word representations during training and achieve better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = np.stack(list(embeddings_index.values()))\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the embedding matrix is created and I need to set some other hyperparameters, before finally creating the network architecture. I want to use a batch gradient descent, so I need to set a batch size and a number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 3\n",
    "embed_size = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a further regularisation technique, I add a reduction in the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In several examples on the internet I have seen that for similar tasks and models they have used LTSM. This led me to disregard my model evaluation from the notebook \"02_model_eval\" and to use too the LTSM instead. \n",
    "The Long Short-Term Memory (LSTM) model is a subtype of Recurrent Neural Networks (RNN). It is used to recognise patterns in data sequences, such as those that appear in sensor data, stock prices or natural language. RNNs are able to do this because, in addition to the actual value, they also include its position in the sequence in the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
    "model.add(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.25 , dropout = 0.25))\n",
    "model.add(LSTM(units=64 , recurrent_dropout = 0.1 , dropout = 0.1))\n",
    "model.add(Dense(units = 32 , activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr = 0.01), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I check the model and get an overview of the structure of the model and the number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training of the model can be carried out.\n",
    "As preparation, I have already trained the model once with 10 Epochs. This took about 24 hours and resulted in an accuracy of 0.9966 and a loss of 0.0093 after the 10 epochs.\n",
    "\n",
    "For the further training of the model, I reduced the number of epochs to 3 so that less time and fewer resources are needed. After the 3 epochs, the accuracy is 0.9904 and the loss is 0.0300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = batch_size , validation_data = (X_dev,y_dev) , epochs = epochs , callbacks = [learning_rate_reduction])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../Machine_Learning2_Project/30_train_model/31_trained_model/31_trained_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By saving the tokeniser as a pickle file, we can load and use it again later without having to run the tokenisation process again. This is especially useful when we want to apply the trained model to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../Machine_Learning2_Project/30_train_model/30_inputs/30_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is simply to check the accuracy of the model on each of the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(X_train,y_train)[1]*100)\n",
    "print(\"Accuracy of the model on Dev Data is - \" , model.evaluate(X_dev,y_dev)[1]*100)\n",
    "print(\"Accuracy of the model on Test Data is - \" , model.evaluate(X_test,y_test)[1]*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs remarkably well on each of the three datasets! Incredibly, it achieves a high accuracy on each of the three sets.\n",
    "\n",
    "** Please make sure that number in \"epochs = [i for i in range(3)]\" is the same as in the training. Otherwise the model will not be loaded correctly. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(3)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Dev Accuracy')\n",
    "ax[0].set_title('Training & Dev Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'go-' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'ro-' , label = 'Dev Loss')\n",
    "ax[1].set_title('Training & Dev Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the loss essentially decreases on each epoch, which could suggest further training may slightly improve accuracy even further. In the first run, where I have used 10 epochs it was even more obvious. You can find more details about it in the README.md file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print(classification_report(y_test, pred, target_names = ['Fake','Not Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows no particular bias to false negatives or false positives. Now, let's try the model on some articles taken from the web. The first is a BBC news article about the Portland protests (not fake), while the second is a well-known fake news article about Hillary Clinton.\n",
    "\n",
    "But to do this I need also some text processing for the text entry. So I will create a function for this and that it is reusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can enter the news and check the prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_title = \"Portland protests: Trump threatens to send officers to more US cities\"\n",
    "real_text = \"President Donald Trump has threatened to send more federal law enforcement officers to major US cities to control ongoing protests.\\\n",
    "Mr Trump on Monday criticised a number of cities run by 'liberal Democrats', including Chicago and New York, saying their leaders were afraid to act.\\\n",
    "He said officers sent to Oregon had done a 'fantastic job' restoring order amid days of protests in Portland.\\\n",
    "Democrats accuse Mr Trump of trying to rally his Conservative base.\\\n",
    "President Trump, a Republican, has been trailing in opinion polls behind his Democratic rival, Joe Biden, ahead of November's election.\\\n",
    "Last month, Mr Trump declared himself the 'president of law and order' in the wake of widespread protests over the death in police custody of African-American man George Floyd.\\\n",
    "Speaking at the White House on Monday, Mr Trump reiterated his call for law and order.\\\n",
    "'We're sending law enforcement,'' he told reporters. 'We can't let this happen to the cities.'\\\n",
    "He specifically named New York City, Chicago, Philadelphia, Detroit, Baltimore and Oakland in discussing problems with violence.\"\n",
    "\n",
    "fake_title = \"FBI Agent, Who Exposed Hillary Clinton Cover-up, Found Dead\"\n",
    "fake_text = \"An FBI Special Agent, who was anticipated to expose the extent of Clinton and Obama malpractice and corruption in the “Operation Fast and Furious” \\\n",
    "cover-up before a US Federal Grand Jury, has been found dead at his home. The FBI official’s wife was also found dead at the scene with the couple both being murdered \\\n",
    "using the 52-year-old agent’s own gun.Special Agent David Raynor was “stabbed multiple times” and “shot twice with his own weapon,” according to local media reports. \\\n",
    "Raynor’s tragic death comes just one day before he was due to testify before a US Federal Grand Jury. \\\n",
    "He was widely expected to testify that Hillary Clinton acted illegally to protect Obama administration crimes while covering up the Fast and Furious scandal. \\\n",
    "Raynor’s wife, Donna Fisher, was also found dead at the scene. An autopsy will be completed to determine the exact cause of death, according to police. According to the \\\n",
    "Baltimore Sun:Authorities, who are offering a $215,000 reward for tips in Suiter’s killing, have struggled to understand what happened. \\\n",
    "The detective was shot with his own gun, which was found at the scene. Two other shots were fired from the gun, and Davis said there were signs of a brief \\\n",
    "struggle.Special Agent Raynor’s suspicious death is the latest in a sequence of disturbing deaths in Baltimore connected to the Clinton/Obama cover-up of \\\n",
    "Operation Fast and Furious.When President Trump took power, the US Justice Department opened another investigation into Operation Fast and Furious as it pertained \\\n",
    "to the Baltimore Police Department and impaneled a US Federal Grand Jury. One of the main witnesses was Detective Sean Suiter, an 18-year veteran of the FBI.However, \\\n",
    "Detective Suiter was gunned down in November, in eerily similar circumstances to Special Agent Raynor, also one day before he could testify. \\\n",
    "Special Agent Raynor was leading US Deputy Attorney General Rod Rosenstein’s and FBI Director Christopher Wray’s investigation into the murder of Detective Sean Suiter. \\\n",
    "Raynor believed Suiter was silenced before he could testify that the Obama administration was criminally complicit in allowing guns to flow into the hands of criminals on the \\\n",
    "Mexican border. \\\n",
    "These guns were involved in the murder of a US Federal Officer, among others, and is seen by investigators as the “Achilles heel of the Obama regime.”The murder of Border \\\n",
    "Patrol Agent Brian Terry is one of but a very few Obama administration crimes that have no statute of limitations as it involved the killing of a US Federal Officer. \\\n",
    "Leaked Wikileaks emails also prove Hillary Clinton was fully knowledgeable about the crime—thus making her liable to criminal charges. \\\n",
    "Last’s week’s bombshell Inspector General’s reports have exposed yet more Hillary Clinton and Obama Administration crimes.The report, that was released last Thursday, \\\n",
    "revealed that the FBI had discovered evidence that Hillary Clinton and the Clinton Foundation had committed “sexual crimes against children.” The report also shows that Obama \\\n",
    "lied to cover-up parts of these investigations that exposed child trafficking.However, the IG report proves that the evidence of these crimes has been covered-up and \\\n",
    "swept under the carpet by those acting at the highest levels.\"\n",
    "\n",
    "# Denoise and tokenise the title and article contents and add them to an array\n",
    "text = [denoise_text(real_title + \" \" + real_text), denoise_text(fake_title + \" \" + fake_text)]\n",
    "\n",
    "tokenized_new = tokenizer.texts_to_sequences(text)\n",
    "X_new = pad_sequences(tokenized_new, maxlen=max_len)\n",
    "\n",
    "# Make predictions on the new examples\n",
    "predictions = np.argmax(model.predict(X_new), axis=1)\n",
    "\n",
    "mapping = {0: 'Not fake',\n",
    "           1: 'Fake'}\n",
    "\n",
    "predictions = np.vectorize(mapping.get)(predictions)\n",
    "\n",
    "print(\"BBC News article is predicted to be: {}\".format(predictions[0]))\n",
    "print(\"Fake news article is predicted to be: {}\".format(predictions[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The model predicts the BBC news article correctly as real news. The fake news article is not predicted correctly. The model predicts it as real news. This is not surprising, because the fake news article is very long and the model is trained with news articles that are much shorter. So the model is not able to predict the fake news article correctly.\n",
    "\n",
    "The solution could be to add longer news articles to the data and train the model again or to shorten the length of entered news so that the model can handle it better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
