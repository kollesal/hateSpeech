# Project work for Python Grundlagen

## Students
Melvin Kurisunkal <br />
Oliver Tanno <br />
Salome Koller <br />

## Module
**Module name:** Python <br />
**Semester:** 2023-HS <br />
**Lecturer:** Maria Pelli <br />

## Project work

### 01 Kontext

#### Hypothesis and Data Definition
**Research Question**: To what extent can machine learning models accurately classify tweets as cyberbullying or non-cyberbullying based on the content and linguistic features, and what key features contribute the most to the classification?

**H0**: Machine learning models cannot accurately classify tweets as cyberbullying or non-cyberbullying based on content and linguistic features, and these features do not significantly contribute to the classification.
**H1**: Machine learning models can accurately classify tweets as cyberbullying or non-cyberbullying based on content and linguistic features, and certain key features play a significant role in the classification process.

#### Categorization of data

**by origin**
Primary Data: We don't use primary data, as we don't collect data ourselves.
Secondary Data: The "cyberbullying_tweets.csv" File is considered as Secondary data. Source: https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification/

The User dataset that is linked to the tweet has been generated by Mockaroo.

**by accessibility**
We only use open data for this project.

**by scale of measure**
The dataset contains only nominal data. There isn't a lot of variety in the dataset.
nominal: The tweets are considered as nominal.

**by structure**
unstructured: the tweets are considered as unstructured.
semi-structured: We don't use semi-structured data.
structured data: after the web scraping and data preparation the data is saved in the MySQL Table and considered as structured.

### 02 Unifying & Transformation
We have 2 Tables: The Tweets and the Users. The Join of this 2 Tables has been done in Postgres. 

The unified and transformed files are accessible in 01_Kontext/10_datasource
**Original CSV**: cyberbullying_tweets.csv
**In Prostgres transformed CSV**: interaction_with_date_and_time.csv

Also, because we only use String variables from the main tweet dataset, and a Classification Case, we don't need to unify and tranform the Dataset.

### 03 Data Cleansing
The Distribution of the Classification has been checked, as well as the search for missing values.
**Result**: The Cyberbulling Types are distributed evenly with a slight lower amount of the class "other_cyberbullying".
There are no missing values in the dataset.

### 04 Analysis & Validation

### 05 Feature Selection & Engineering
The following Feature Engineering has been made:
- Text statistics (Average lengths of strings)
- Pattern Creation (One-Hot Encoding)
- Text Lengths

### 06 EDA
The step is so late, because we only have String values in the dataset. At first, we needed to create some Int values to make a small EDA evaluation. We kept this part short, because it doesn't analyse the original dataset and is therefore not 100% accurate because it has been created through the feature engineering.
The following analysis has been made: 
- Non Graphical Univariate EDA
- Non Graphical Multivariate EDA
- Graphical Univariate EDA
- Graphical Multivariate EDA

### 07 Anwendung in Machine Learning

### 08 Anwendung von XAI â€“ Techniken









