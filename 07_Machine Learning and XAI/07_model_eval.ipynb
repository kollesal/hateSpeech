{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning & XAI\n",
    "Wir möchten nun herausfinden, wie die verschiedenen Modelle mit den Daten perfomen und welche Unterschiede wir entdecken können.\n",
    "\n",
    "Hinweis zu den Quellen:\n",
    "In den letzten Semestern an der ZHAW haben wir uns in verschiedenen Modulen wie z.B. Data Management, Data Science Introduction, Scientific Programming, Machine Learning I, Machine Learning II und Model Deployment & Maintenance mit dem Thema Large Languages Models beschäftigt. Je nach Modul eher theoretisch mit Statisik und Konzepten oder eher praktisch mit Python, Keras, Tensorflow, Huggingface, etc. in entsprechenden Projekten. Für dieses Notebook habe ich entsprechenden Ansätze und Code bei Bedarf verwendet, dabei habe ich die entsprechenden Module als Quelle angegeben, egal ob ich \"nur\" das theoretische Konzept oder auch Teile des Codes verwendet habe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import von benötigten Libraries & dem Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Libraries werden für die Bearbeitung des vorliegenden Notebooks verwendet. Bitte stellen Sie sicher, dass deren Installation mithilfe von `pip install <library>` sichergestellt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\olive\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk \n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Load Huggingface transformers\n",
    "from transformers import TFBertModel,  BertConfig, BertTokenizerFast, TFAutoModel\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "import re,string,unicodedata\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Bewertung von Modelen\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#XAI Anwendungen\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Attention\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset\n",
    "Als ersten Schritt importiere ich das Datenset des vorhergebenen Schrittes 06_Feature Selection & Engineering\n",
    "\n",
    "Quellen:\n",
    "- Code validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_df = pd.read_csv('..\\\\06_Feature Selection & Engineering\\\\06_dataset_tweets_featured.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz ist zu klein um ein ganze Large Language Model zu trainieren. Daher verwende ich das bereits trainierte Model \"bert-base-uncased\" von Huggingface inkl. entsprechendem Tokenizer dazu um das Model für den vorliegenden Datensatz Fine zu tunen. \n",
    "\n",
    "Das Bert-Model habe ich bereits im Modul \"Model Deployment & Maintenance\" im letzten Semester verwendet, daher habe ich entschieden es hier wieder zu verwenden.\n",
    "\n",
    "Quellen:\n",
    "- Model Deployment & Maintenance, ZHAW, FS2023\n",
    "- huggingface.co\n",
    "- Code validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "max_length = 140\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "#config.output_hidden_states = False\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
    "bert = TFAutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das weitere Vorgehen mit dem Model erstelle ich zwei Eingabeschichten (input_ids und attention_mask), um die Tweets zu verarbeiten. Das BERT-Modell wird dann auf diese Eingabeschichten angewendet, und der Ausgang wird in der Variable x gespeichert.\n",
    "\n",
    "Quellen:\n",
    "- Model Deployment & Maintenance, ZHAW, FS2023\n",
    "- Code validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32') \n",
    "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "x = bert.bert(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für das Training des Models verwende ich die bereinigten Tweet-Texte und Klassifizierung in der Spalte cyberbulling_type. Daher kann ich die restlichen Spalten aus dem Dataframe entfernen. Da ich ein Pretrained Model verwende, dass Kleinschrebung ausgelegt ist, wandle ich auch alle Tweet-Texte in Kleinbuchstaben um.\n",
    "\n",
    "Quellen:\n",
    "- Code validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>@GYU WHAT IS THAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other_cyberbullying</td>\n",
       "      <td>@STOCKPUTOUT YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other_cyberbullying</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "      <td>@BLACKAMAZON EXACTLY THIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>@ODDTANKOUT HTTP   T CO KMMJEUME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64339</th>\n",
       "      <td>ethnicity</td>\n",
       "      <td>ONLY THING THAT HEATS MY HEAD MORE IS WHEN I SEE A  BLACK PEOPLE ACTING LIKE  NIGGERS  AND B  ME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64340</th>\n",
       "      <td>age</td>\n",
       "      <td>FOUND OUT THE GIRL WHO SPREAD (TRUE) RUMOURS ABOUT ME BEING BI AND KINDA BULLIED ME ABOUT IT IN ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64341</th>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>NIÑAS  REINAS DEL “BULLYING” EN ESCUELAS PRIVADAS HTTP   T CO VKAZXI    Y LAS Q SE CREEN QUEEN B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64342</th>\n",
       "      <td>religion</td>\n",
       "      <td>@DIANH AS USUAL  YOU ARE A MUSLIM LIAR MAKING ANY EXCUSES FOR A RELIGION OF BARBARITY  MURDER  H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64343</th>\n",
       "      <td>other_cyberbullying</td>\n",
       "      <td>THOSE  MAKING IT THROUGH TO THE NEXT ROUND  COLIN HAS JUST LOST ALL CREDIBILITY IN MY EYES  MKR ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64344 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cyberbullying_type  \\\n",
       "0        not_cyberbullying   \n",
       "1      other_cyberbullying   \n",
       "2      other_cyberbullying   \n",
       "3                     none   \n",
       "4                     none   \n",
       "...                    ...   \n",
       "64339            ethnicity   \n",
       "64340                  age   \n",
       "64341    not_cyberbullying   \n",
       "64342             religion   \n",
       "64343  other_cyberbullying   \n",
       "\n",
       "                                                                                                tweet_text  \n",
       "0                                                                                       @GYU WHAT IS THAT   \n",
       "1                                                                                         @STOCKPUTOUT YES  \n",
       "2                                                                                                           \n",
       "3                                                                               @BLACKAMAZON EXACTLY THIS   \n",
       "4                                                                         @ODDTANKOUT HTTP   T CO KMMJEUME  \n",
       "...                                                                                                    ...  \n",
       "64339  ONLY THING THAT HEATS MY HEAD MORE IS WHEN I SEE A  BLACK PEOPLE ACTING LIKE  NIGGERS  AND B  ME...  \n",
       "64340  FOUND OUT THE GIRL WHO SPREAD (TRUE) RUMOURS ABOUT ME BEING BI AND KINDA BULLIED ME ABOUT IT IN ...  \n",
       "64341  NIÑAS  REINAS DEL “BULLYING” EN ESCUELAS PRIVADAS HTTP   T CO VKAZXI    Y LAS Q SE CREEN QUEEN B...  \n",
       "64342  @DIANH AS USUAL  YOU ARE A MUSLIM LIAR MAKING ANY EXCUSES FOR A RELIGION OF BARBARITY  MURDER  H...  \n",
       "64343  THOSE  MAKING IT THROUGH TO THE NEXT ROUND  COLIN HAS JUST LOST ALL CREDIBILITY IN MY EYES  MKR ...  \n",
       "\n",
       "[64344 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data_df = cleaned_data_df.drop(columns=['interaction_id', 'tweet_id', 'senderuser_id', 'receiveruser_id', 'interaction_timestamp', 'char_count', 'harass', 'cyberstalk', 'doxing', 'exclusion', 'impersonation', 'trolling', 'hateSpeech', 'threats', 'flaming', 'outing', 'word_count', 'avg_word_length', 'avg_sentence_length', 'punctuation_count'])\n",
    "cleaned_data_df['tweet_text'] = cleaned_data_df['tweet_text'].str.lower()\n",
    "cleaned_data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit das Finetuning auch nur mit Zeilen mit effektivem Inhalt der Spalte tweet_text geschieht und es keine Verzerrungen gibt, stelle ich nochmals sicher, dass die Zeilen mit leerem Inhalt in der entsprechenden Zelle in der Spalte tweet_text komplett entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_df = cleaned_data_df.dropna(subset=['tweet_text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es sich hier um mehrere Klassen handelt und ich damit das Model trainieren möchte nutze ich die Funktion \"get_dumies\" um sie für das Machine Learning zu optimieren. Die Funktion get_dummies in Pandas wird verwendet, um Dummy-Variablen für kategorische Spalten zu erstellen, wodurch diese Spalten in eine binäre (0 oder 1) Darstellung umgewandelt werden.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning I, ZHAW, HS2022\n",
    "- Code validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type_age</th>\n",
       "      <th>cyberbullying_type_ethnicity</th>\n",
       "      <th>cyberbullying_type_gender</th>\n",
       "      <th>cyberbullying_type_none</th>\n",
       "      <th>cyberbullying_type_not_cyberbullying</th>\n",
       "      <th>cyberbullying_type_other_cyberbullying</th>\n",
       "      <th>cyberbullying_type_racism</th>\n",
       "      <th>cyberbullying_type_religion</th>\n",
       "      <th>cyberbullying_type_sexism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@GYU WHAT IS THAT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@STOCKPUTOUT YES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@BLACKAMAZON EXACTLY THIS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@ODDTANKOUT HTTP   T CO KMMJEUME</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64339</th>\n",
       "      <td>ONLY THING THAT HEATS MY HEAD MORE IS WHEN I SEE A  BLACK PEOPLE ACTING LIKE  NIGGERS  AND B  ME...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64340</th>\n",
       "      <td>FOUND OUT THE GIRL WHO SPREAD (TRUE) RUMOURS ABOUT ME BEING BI AND KINDA BULLIED ME ABOUT IT IN ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64341</th>\n",
       "      <td>NIÑAS  REINAS DEL “BULLYING” EN ESCUELAS PRIVADAS HTTP   T CO VKAZXI    Y LAS Q SE CREEN QUEEN B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64342</th>\n",
       "      <td>@DIANH AS USUAL  YOU ARE A MUSLIM LIAR MAKING ANY EXCUSES FOR A RELIGION OF BARBARITY  MURDER  H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64343</th>\n",
       "      <td>THOSE  MAKING IT THROUGH TO THE NEXT ROUND  COLIN HAS JUST LOST ALL CREDIBILITY IN MY EYES  MKR ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64343 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                tweet_text  \\\n",
       "0                                                                                       @GYU WHAT IS THAT    \n",
       "1                                                                                         @STOCKPUTOUT YES   \n",
       "2                                                                                                            \n",
       "3                                                                               @BLACKAMAZON EXACTLY THIS    \n",
       "4                                                                         @ODDTANKOUT HTTP   T CO KMMJEUME   \n",
       "...                                                                                                    ...   \n",
       "64339  ONLY THING THAT HEATS MY HEAD MORE IS WHEN I SEE A  BLACK PEOPLE ACTING LIKE  NIGGERS  AND B  ME...   \n",
       "64340  FOUND OUT THE GIRL WHO SPREAD (TRUE) RUMOURS ABOUT ME BEING BI AND KINDA BULLIED ME ABOUT IT IN ...   \n",
       "64341  NIÑAS  REINAS DEL “BULLYING” EN ESCUELAS PRIVADAS HTTP   T CO VKAZXI    Y LAS Q SE CREEN QUEEN B...   \n",
       "64342  @DIANH AS USUAL  YOU ARE A MUSLIM LIAR MAKING ANY EXCUSES FOR A RELIGION OF BARBARITY  MURDER  H...   \n",
       "64343  THOSE  MAKING IT THROUGH TO THE NEXT ROUND  COLIN HAS JUST LOST ALL CREDIBILITY IN MY EYES  MKR ...   \n",
       "\n",
       "       cyberbullying_type_age  cyberbullying_type_ethnicity  \\\n",
       "0                           0                             0   \n",
       "1                           0                             0   \n",
       "2                           0                             0   \n",
       "3                           0                             0   \n",
       "4                           0                             0   \n",
       "...                       ...                           ...   \n",
       "64339                       0                             1   \n",
       "64340                       1                             0   \n",
       "64341                       0                             0   \n",
       "64342                       0                             0   \n",
       "64343                       0                             0   \n",
       "\n",
       "       cyberbullying_type_gender  cyberbullying_type_none  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "2                              0                        0   \n",
       "3                              0                        1   \n",
       "4                              0                        1   \n",
       "...                          ...                      ...   \n",
       "64339                          0                        0   \n",
       "64340                          0                        0   \n",
       "64341                          0                        0   \n",
       "64342                          0                        0   \n",
       "64343                          0                        0   \n",
       "\n",
       "       cyberbullying_type_not_cyberbullying  \\\n",
       "0                                         1   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "64339                                     0   \n",
       "64340                                     0   \n",
       "64341                                     1   \n",
       "64342                                     0   \n",
       "64343                                     0   \n",
       "\n",
       "       cyberbullying_type_other_cyberbullying  cyberbullying_type_racism  \\\n",
       "0                                           0                          0   \n",
       "1                                           1                          0   \n",
       "2                                           1                          0   \n",
       "3                                           0                          0   \n",
       "4                                           0                          0   \n",
       "...                                       ...                        ...   \n",
       "64339                                       0                          0   \n",
       "64340                                       0                          0   \n",
       "64341                                       0                          0   \n",
       "64342                                       0                          0   \n",
       "64343                                       1                          0   \n",
       "\n",
       "       cyberbullying_type_religion  cyberbullying_type_sexism  \n",
       "0                                0                          0  \n",
       "1                                0                          0  \n",
       "2                                0                          0  \n",
       "3                                0                          0  \n",
       "4                                0                          0  \n",
       "...                            ...                        ...  \n",
       "64339                            0                          0  \n",
       "64340                            0                          0  \n",
       "64341                            0                          0  \n",
       "64342                            1                          0  \n",
       "64343                            0                          0  \n",
       "\n",
       "[64343 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_la = pd.get_dummies(cleaned_data_df, columns = ['cyberbullying_type'])\n",
    "df_la"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden nun die tweet_texte in train_sentences übertragen und die Klassen für das Finetuning vorbereitet. Insgesamt wird dieses Setup oft in multiklassigen Klassifikationsaufgaben verwendet, bei denen für jeden Text mehrere Klassenlabels vorhergesagt werden sollen. Das Modell wird dann darauf trainiert, Muster in den Texten zu lernen und die relevanten Klassen für jeden Text vorherzusagen.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Code validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = cleaned_data_df[\"tweet_text\"].values\n",
    "list_classes = ['cyberbullying_type_age','cyberbullying_type_ethnicity','cyberbullying_type_gender','cyberbullying_type_not_cyberbullying','cyberbullying_type_other_cyberbullying','cyberbullying_type_religion']\n",
    "train_y = df_la[list_classes].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sollen nun die Textdaten verarbeitet werden wobei daraus relevante Merkmale extrahiert werden sollen und dann versucht wird, auf dessen Basis Wahrscheinlichkeiten für verschiedene Klassen vorherzusagen.\n",
    "\n",
    "Quellen:\n",
    "- Model Deployment & Maintenance, ZHAW, FS2023\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Code opimiert und validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['attention_mask[0][0]',         \n",
      "                                thPoolingAndCrossAt               'input_ids[0][0]']              \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 768)         0           ['bert[0][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 6)            4614        ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,486,854\n",
      "Trainable params: 109,486,854\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#x2 =Dense(512, activation='relu')(x[1])\n",
    "x2 = GlobalAveragePooling1D()(x[0])\n",
    "#x3 = Dropout(0.5)(x2)\n",
    "y =Dense(len(list_classes), activation='sigmoid', name='outputs')(x2)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=y)\n",
    "#model.layers[2].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Adam-Optimizer ist eine Variante des stochastischen Gradientenabstiegs (SGD), der häufig für das Training von neuronalen Netzwerken verwendet wird. Die Lernrate steuert die Größe der Schritte, die der Optimierer während des Trainings macht, und 1e-5 ist eine typische Anfangs-Lernrate. Dieser Code das neuronale Netzwerk darauf vor, auf die gegebene Aufgabe mit einem bestimmten Optimierer und einer spezifischen Lernrate trainiert zu werden.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Code opimiert und validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=1e-5)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Inputs werden als Token an das BERT-Modell übergeben, damit das Model die Inhalte der Tweets verarbeiten kann. Die Ausgabe des Codes ist ein Dictionary von TensorFlow-Tensoren, das die tokenisierten Sequenzen ('input_ids') enthält.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Code opimiert und validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input \n",
    "x = tokenizer(\n",
    "    text=list(train_sentences),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_length,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit vorbereiteten Daten kann nun das Model trainiert werden. Dazu verwende ich die Fit-Funktion. Das ist nun der verarbeitende Schritt. Bitte beachten Sie dass das Training je nach Hardware einige Zeit in Anspruch nehmen kann. Auf meinem PC hat das Training mit einem Epochs ca. 10 Stunden gedauert und eine Accuracy von ca. 0.58 erreicht. Daher empfiehlt es sich das Model mit ca. 3 Epochs zu trainieren und anschliessend zu speichern.\n",
    "\n",
    "Quellen:\n",
    "- Model Deployment & Maintenance, ZHAW, FS2023\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Code opimiert und validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "1006/1006 [==============================] - 42531s 42s/step - loss: 0.1510 - accuracy: 0.5898 - val_loss: 0.1236 - val_accuracy: 0.6251\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
    "    #x={'input_ids': x['input_ids']},\n",
    "    y={'outputs': train_y},\n",
    "    validation_split=0.5,\n",
    "    batch_size=32,\n",
    "    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"07_Anwendung in Machine Learning/Finetuning_BERT_Twitter\")\n",
    "\n",
    "# Laden des gespeicherten Modells\n",
    "loaded_model = keras.models.load_model(\n",
    "    \"07_Anwendung in Machine Learning/Finetuning_BERT_Twitter\"\n",
    ")\n",
    "\n",
    "# Jetzt kannst du das geladene Modell für Vorhersagen verwenden\n",
    "# Zum Beispiel: loaded_model.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Überprüfung des Models splitte ich den Datensatz in einen Trainings- und Testdatensatz.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Code opimiert und validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data_df['tweet_text'], all_data_df['cyberbullying_type'],\n",
    "                                                    test_size = 0.2, random_state = 42)\n",
    "print(f'Data Split done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Vectorizer wird nun auf die Daten angepasst, um das Vokabular zu erstellen und die TF-IDF-Gewichtungen zu berechnen.\n",
    "\n",
    "Quellen:\n",
    "- Code opimiert und validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=500000)\n",
    "vectorizer.fit(X_train)\n",
    "print(f'Vectorizer fitted.')\n",
    "print('No. of feature_words: ', len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectoriser.transform(X_train)\n",
    "X_test  = vectoriser.transform(X_test)\n",
    "print(f'Data Transformed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion model_Evaluate führt eine Evaluierung eines Modells durch und gibt verschiedene Leistungsmetriken aus. Dies nutze ich als Basis bzw. Ausgangslage für Evaluierung mit den weiteren Modellen.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Code opimiert und validiert mit Chat-GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Evaluate(model):\n",
    "    \n",
    "    # Predict values for Test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print the evaluation metrics for the dataset.\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm=confusion_matrix(y_pred , y_test)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Reds)\n",
    "    plt.xticks(range(2), ['Negative',  'Positive'], fontsize=16,color='black')\n",
    "    plt.yticks(range(2), ['Negative', 'Positive'], fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelbewertung"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "Der Decision Tree Classifier ist ein Supervised Machine Learning Algorithmus, der für Klassifikationsaufgaben verwendet wird. Seine Stärke liegt in seiner Fähigkeit, komplexe Entscheidungsregeln auf Basis der Trainingsdaten zu erlernen und präzise Vorhersagen zu treffen. Die Entscheidungsregeln werden in Form eines Baumes dargestellt, wobei jeder innere Knoten eine Entscheidung darstellt und jeder Blattknoten ein Ergebnis darstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc= DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "model_Evaluate(dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da es hier um ein Model mit mehreren Klassen handelt, nutze die Methode \"OneVSOneClassifier\" um die Klassen zu klassifizieren. Die Methode \"OneVSOneClassifier\" ist eine Methode, die eine Reihe von binären Klassifikatoren erstellt, die jeweils zwei Klassen unterscheiden. Die Entscheidung wird dann durch Abstimmung getroffen.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning II, ZHAW, FS2023\n",
    "- Chat-GPT 3.5\n",
    "- Code optimiert mit Github Co-Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = label_binarize(dtc.predict(X_test), classes=dtc.classes_)\n",
    "print(y_score)\n",
    "\n",
    "# Binarisieren Sie die multiklassen Labels für die Testdaten\n",
    "y_test_bin = label_binarize(y_test, classes=dtc.classes_)\n",
    "print(y_test_bin)\n",
    "\n",
    "# Berechnung der ROC-Kurve für jede Klasse\n",
    "fpr_micro, tpr_micro, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr_micro, tpr_micro, color='darkred', lw=2, label='Micro-average ROC curve (area = {:0.2f})'.format(roc_auc_micro))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree Classifier (Micro-average)')\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Die logistische Regression ist einfach, interpretierbar und effektiv für binäre Klassifikationsaufgaben. Wenn es um mehr als zwei Klassen geht, kann die logistische Regression auf verschiedene Arten erweitert werden, wie z. B. die \"One-vs-Rest\" oder \"Multinomial\" Ansätze.\n",
    "\n",
    "Quellen:\n",
    "- Machine Learning I, ZHAW, HS2022\n",
    "- Chat-GPT 3.5\n",
    "- Code optimiert mit Github Co-Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "model_Evaluate(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = lr.predict_proba(X_test)\n",
    "y_test_bin = label_binarize(y_test, classes=lr.classes_)\n",
    "\n",
    "fpr_macro = dict()\n",
    "tpr_macro = dict()\n",
    "roc_auc_macro = dict()\n",
    "for i in range(len(lr.classes_)):\n",
    "    fpr_macro[i], tpr_macro[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc_macro[i] = auc(fpr_macro[i], tpr_macro[i])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(len(lr.classes_)):\n",
    "    plt.plot(\n",
    "        fpr_macro[i],\n",
    "        tpr_macro[i],\n",
    "        lw=2,\n",
    "        label=\"ROC curve (area = {:0.2f}) for class {}\".format(roc_auc_macro[i], i),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Logistic Regression (Macro-average)\")\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier\n",
    "Der K-Nearest Neighbors Classifier ist ein einfacher und intuitiver Algorithmus für maschinelles Lernen, der für Klassifikations- und Regressionsaufgaben verwendet wird. Der KNN-Classifier ist besonders nützlich in Situationen, in denen die Entscheidungsgrenze nicht linear ist und die Datenpunkte nah beieinander gruppiert sind. Es ist wichtig, die Anzahl der Nachbarn und die Entfernungsmaße sorgfältig zu wählen, um optimale Ergebnisse zu erzielen.\n",
    "Diesen Ansatz habe ich gewählt, da ich die Vermutung habe, dass die Datenpunkte der verschiedenen Klassen nahe beieinander gruppiert sein könnten.\n",
    "\n",
    "Quellen:\n",
    "- Chat-GPT 3.5\n",
    "- Code optimiert mit Github Co-Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "model_Evaluate(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = knn.predict_proba(X_test)\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr_macro = dict()\n",
    "tpr_macro = dict()\n",
    "roc_auc_macro = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr_macro[i], tpr_macro[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "\n",
    "    roc_auc_macro[i] = auc(fpr_macro[i], tpr_macro[i])\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(n_classes):\n",
    "\n",
    "    plt.plot(\n",
    "        fpr_macro[i],\n",
    "        tpr_macro[i],\n",
    "        lw=2,\n",
    "        label=\"ROC curve (area = {:0.2f}) for class {}\".format(roc_auc_macro[i], i),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"K-Nearest Neighbors (Macro-average)\")\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier\n",
    "AdaBoost ist ein sogenannter Boosting-Algorithmus, der auf dem Prinzip des Schichtens von Klassifikatoren basiert.\n",
    "Er verwendet eine Reihe von schwachen Klassifikatoren und kombiniert ihre Vorhersagen, um eine genauere Gesamtvorhersage zu erzielen.\n",
    "\n",
    "Quellen:\n",
    "- Chat-GPT 3.5\n",
    "- Code optimiert mit Github Co-Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train,y_train)\n",
    "model_Evaluate(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = abc.predict_proba(X_test)\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr_micro, tpr_micro, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "fpr_macro = dict()\n",
    "tpr_macro = dict()\n",
    "roc_auc_macro = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr_macro[i], tpr_macro[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc_macro[i] = auc(fpr_macro[i], tpr_macro[i])\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(\n",
    "        fpr_macro[i],\n",
    "        tpr_macro[i],\n",
    "        lw=2,\n",
    "        label=\"ROC curve (area = {:0.2f}) for class {}\".format(roc_auc_macro[i], i),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"AdaBoost Classifier (Macro-average)\")\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiNomial NB\n",
    "Multinomial Naive Bayes (MNB) ist ein probabilistischer Klassifikationsalgorithmus, der auf dem Bayes-Theorem basiert und insbesondere für Textklassifikationsprobleme geeignet ist. Multinomial Naive Bayes ist besonders nützlich für Textklassifikationsaufgaben. Daher habe ich diesen Ansatz gewählt um das vorliegende Modell ebenfalls mit diesem Ansatz zu überprüfen.\n",
    "\n",
    "Quellen:\n",
    "- Chat-GPT 3.5\n",
    "- Code optimiert mit Github Co-Pilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "model_Evaluate(mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = mnb.predict_proba(X_test)\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr_micro, tpr_micro, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(7, 7))\n",
    "axes.plot(\n",
    "    fpr_micro,\n",
    "    tpr_micro,\n",
    "    color=\"darkred\",\n",
    "    lw=2,\n",
    "    label=\"Micro-average ROC curve (area = {:0.2f})\".format(roc_auc_micro),\n",
    ")\n",
    "axes.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "axes.set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\n",
    "axes.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Multi-Nomial Naive Bayes (Micro-average)\",\n",
    ")\n",
    "axes.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier\n",
    "Gradient Boosting ist eine Ensemble-Methode, die darauf abzielt, schwache Elemente zu einem starken Element zu kombinieren. Der Gradient Boosting Classifier ist speziell für Klassifikationsaufgaben ausgelegt und da es sich hier um eine Klassifikationsaufgabe handelt, habe ich diesen Ansatz gewählt um das vorliegende Modell ebenfalls mit diesem Ansatz zu überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(X_train,y_train)\n",
    "model_Evaluate(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        lw=2,\n",
    "        label=\"ROC curve (area = {:0.2f}) for class {}\".format(roc_auc[i], i),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Gradient Boosting Classifier (One-vs-Rest ROC)\")\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Clssifier\n",
    "Der Random Forest Classifier ist eine Methode, die aus einer Sammlung von Entscheidungsbäumen besteht. Diese Bäume werden unabhängig voneinander trainiert, und ihre Vorhersagen werden kombiniert, um die Gesamtvorhersage zu verbessern. Der Random Forest Classifier ist speziell für Klassifikationsaufgaben ausgelegt, daher habe ich es ebenfalls gewählt um das vorliegende Modell ebenfalls mit diesem Ansatz zu überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RFC(random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "model_Evaluate(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc = rfc.predict_proba(X_test)[:,1]\n",
    "fpr_rfc,tpr_rfc,_ = roc_curve(y_test.values,pred_rfc)\n",
    "roc_auc_rfc = auc(fpr_rfc,tpr_rfc)\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, 1,figsize=(7,7))\n",
    "axes.plot(fpr_rfc, tpr_rfc, color='darkred', lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc_rfc))\n",
    "axes.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes.set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\n",
    "axes.set(xlabel ='False Positive Rate', ylabel = 'True Positive Rate', title = 'Random Forest Classifer')\n",
    "axes.legend(loc='lower right', fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI Modelanalyse\n",
    "XAI steht für Explainable Artificial Intelligence. Diese Technik konzentriert sich darauf, komplexe KI-Modelle und deren Entscheidungen transparenter und nachvollziehbarer zu machen. Das Ziel von XAI ist es, das \"Black-Box\"-Problem anzugehen, bei dem tiefgreifende Modelle, insbesondere neuronale Netzwerke, als schwer interpretierbar gelten. (Chat-GPT 3.5, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(max_length,), dtype=\"int32\")\n",
    "embedding_layer = Embedding(input_dim=500000, output_dim=128, input_length=max_length)(\n",
    "    input_layer\n",
    ")\n",
    "\n",
    "# Define the LSTM layer\n",
    "lstm_layer = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(embedding_layer)\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Dense(1, activation=\"sigmoid\")(lstm_layer)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Print test accuracy\n",
    "print(\"\\n\", \"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 5), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 5), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 5), history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 5), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "# Annahme: model ist Ihr LSTM-Modell\n",
    "y_score = model.predict(X_test)\n",
    "\n",
    "# Binarisieren Sie die multiklassen Labels für die Testdaten\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "# Berechnung der Mikro-Durchschnitt-ROC-Kurve\n",
    "fpr_micro, tpr_micro, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "# Plotting\n",
    "f, axes = plt.subplots(1, 1, figsize=(7, 7))\n",
    "axes.plot(\n",
    "    fpr_micro,\n",
    "    tpr_micro,\n",
    "    color=\"darkred\",\n",
    "    lw=2,\n",
    "    label=\"Micro-average ROC curve (area = {:0.2f})\".format(roc_auc_micro),\n",
    ")\n",
    "axes.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "axes.set(xlim=[-0.01, 1.0], ylim=[-0.01, 1.05])\n",
    "axes.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"LSTM (Micro-average)\",\n",
    ")\n",
    "axes.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneVsRestClassifier(model)\n",
    "y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "n_classes = len(np.unique(y_test))\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        lw=2,\n",
    "        label=\"ROC curve (area = {:0.2f}) for class {}\".format(roc_auc[i], i),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"LSTM (One-vs-Rest ROC)\")\n",
    "plt.legend(loc=\"lower right\", fontsize=13)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
